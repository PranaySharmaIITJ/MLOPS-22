================================
Recognizing hand-written digits
================================

This example shows how scikit-learn can be used to recognize images of
hand-written digits, from 0-9.

shape of data: (1797, 8, 8)
shape of single image: (8, 8)


data: (1797, 64)

 ====================

run_0:
gamma: 0.001 | kernel:rbf | c:1

Saving the best model for this run
gamma: 0.001 | kernel:rbf | c:10

Saving the best model for this run
gamma: 0.001 | kernel:linear | c:1
gamma: 0.001 | kernel:linear | c:10
gamma: 0.01 | kernel:rbf | c:1
gamma: 0.01 | kernel:rbf | c:10
gamma: 0.01 | kernel:linear | c:1
gamma: 0.01 | kernel:linear | c:10


best validation f1 score is 0.9963 for optimal values of gamma 0.001 | kernel:rbf | c:10
        best scores on train/val/test: [1.0, 0.982, 0.989]
hyper_param, train_f1, val_f1, test_f1
(0.001, 'rbf', 1) [0.9976, 0.9926, 0.9961]
(0.001, 'rbf', 10) [1.0, 0.9963, 0.9961]
(0.001, 'linear', 1) [1.0, 0.982, 0.989]
(0.001, 'linear', 10) [1.0, 0.982, 0.989]
(0.01, 'rbf', 1) [1.0, 0.8264, 0.8106]
(0.01, 'rbf', 10) [1.0, 0.8526, 0.8136]
(0.01, 'linear', 1) [1.0, 0.982, 0.989]
(0.01, 'linear', 10) [1.0, 0.982, 0.989]

 ====================

run_1:
gamma: 0.001 | kernel:rbf | c:1

Saving the best model for this run
gamma: 0.001 | kernel:rbf | c:10
gamma: 0.001 | kernel:linear | c:1
gamma: 0.001 | kernel:linear | c:10
gamma: 0.01 | kernel:rbf | c:1
gamma: 0.01 | kernel:rbf | c:10
gamma: 0.01 | kernel:linear | c:1
gamma: 0.01 | kernel:linear | c:10


best validation f1 score is 0.9802 for optimal values of gamma 0.001 | kernel:rbf | c:1
        best scores on train/val/test: [1.0, 0.9756, 0.9846]
hyper_param, train_f1, val_f1, test_f1
(0.001, 'rbf', 1) [0.9984, 0.9802, 0.9958]
(0.001, 'rbf', 10) [1.0, 0.9802, 0.9958]
(0.001, 'linear', 1) [1.0, 0.9756, 0.9846]
(0.001, 'linear', 10) [1.0, 0.9756, 0.9846]
(0.01, 'rbf', 1) [1.0, 0.8381, 0.8639]
(0.01, 'rbf', 10) [1.0, 0.8408, 0.8695]
(0.01, 'linear', 1) [1.0, 0.9756, 0.9846]
(0.01, 'linear', 10) [1.0, 0.9756, 0.9846]

 ====================

run_2:
gamma: 0.001 | kernel:rbf | c:1

Saving the best model for this run
gamma: 0.001 | kernel:rbf | c:10
gamma: 0.001 | kernel:linear | c:1
gamma: 0.001 | kernel:linear | c:10
gamma: 0.01 | kernel:rbf | c:1
gamma: 0.01 | kernel:rbf | c:10
gamma: 0.01 | kernel:linear | c:1
gamma: 0.01 | kernel:linear | c:10


best validation f1 score is 0.9959 for optimal values of gamma 0.001 | kernel:rbf | c:1
        best scores on train/val/test: [1.0, 0.9809, 0.9582]
hyper_param, train_f1, val_f1, test_f1
(0.001, 'rbf', 1) [0.9984, 0.9959, 0.9866]
(0.001, 'rbf', 10) [1.0, 0.9959, 0.9867]
(0.001, 'linear', 1) [1.0, 0.9809, 0.9582]
(0.001, 'linear', 10) [1.0, 0.9809, 0.9582]
(0.01, 'rbf', 1) [1.0, 0.7943, 0.7736]
(0.01, 'rbf', 10) [1.0, 0.7969, 0.7898]
(0.01, 'linear', 1) [1.0, 0.9809, 0.9582]
(0.01, 'linear', 10) [1.0, 0.9809, 0.9582]

 ====================

hyper_param, [run1_f1: train/val/test] [run2_f1: train/val/test], [run3_f1: train/val/test]
(0.001, 'rbf', 1)       [0.9976, 0.9926, 0.9961]        [0.9984, 0.9802, 0.9958]        [0.9984, 0.9959, 0.9866]
(0.001, 'rbf', 10)      [1.0, 0.9963, 0.9961]   [1.0, 0.9802, 0.9958]   [1.0, 0.9959, 0.9867]
(0.001, 'linear', 1)    [1.0, 0.982, 0.989]     [1.0, 0.9756, 0.9846]   [1.0, 0.9809, 0.9582]
(0.001, 'linear', 10)   [1.0, 0.982, 0.989]     [1.0, 0.9756, 0.9846]   [1.0, 0.9809, 0.9582]
(0.01, 'rbf', 1)        [1.0, 0.8264, 0.8106]   [1.0, 0.8381, 0.8639]   [1.0, 0.7943, 0.7736]
(0.01, 'rbf', 10)       [1.0, 0.8526, 0.8136]   [1.0, 0.8408, 0.8695]   [1.0, 0.7969, 0.7898]
(0.01, 'linear', 1)     [1.0, 0.982, 0.989]     [1.0, 0.9756, 0.9846]   [1.0, 0.9809, 0.9582]
(0.01, 'linear', 10)    [1.0, 0.982, 0.989]     [1.0, 0.9756, 0.9846]   [1.0, 0.9809, 0.9582]
